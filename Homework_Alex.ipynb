{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.phrases import Phrases,Phraser\n",
    "from gensim.summarization import keywords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.collocations import *\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "import RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_create(adds=[]):\n",
    "    sw=stopwords.words('english')\n",
    "    punc=list(punctuation)\n",
    "    sw.extend(adds)\n",
    "    sw.extend(punc)\n",
    "    return sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef word_rank(txt,adds=[],stem_method='snowball',rank=10):\\n    sw=stopword_create(adds)\\n    w=word_tokenize(txt)\\n    if stem_method=='porter':\\n        ps=PorterStemmer()\\n        w=[ps.stem(i) for i in w if i not in sw]\\n    elif stem_method=='snowball':\\n        ss=SnowballStemmer('english')\\n        w=[ss.stem(i) for i in w if i not in sw]\\n    elif stem_method=='':\\n        w=[i for i in w if i not in sw]\\n    result=pd.Series(w).value_counts()\\n    return result.head(rank)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def word_rank(txt,adds=[],stem_method='snowball',rank=10):\n",
    "    sw=stopword_create(adds)\n",
    "    w=word_tokenize(txt)\n",
    "    if stem_method=='porter':\n",
    "        ps=PorterStemmer()\n",
    "        w=[ps.stem(i) for i in w if i not in sw]\n",
    "    elif stem_method=='snowball':\n",
    "        ss=SnowballStemmer('english')\n",
    "        w=[ss.stem(i) for i in w if i not in sw]\n",
    "    elif stem_method=='':\n",
    "        w=[i for i in w if i not in sw]\n",
    "    result=pd.Series(w).value_counts()\n",
    "    return result.head(rank)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef phrase_rank(txt,adds=[],stem_method='snowball',rank=5):\\n    sw=stopword_create(adds)\\n    w=word_tokenize(txt)    \\n    if stem_method=='porter':\\n        ps=PorterStemmer()\\n        w=[ps.stem(i) for i in w if i not in sw]\\n    elif stem_method=='snowball':\\n        ss=SnowballStemmer('english')\\n        w=[ss.stem(i) for i in w if i not in sw]\\n    elif stem_method=='':\\n        w=[i for i in w if i not in sw]\\n    trigram_measures = nltk.collocations.TrigramAssocMeasures()\\n    bigram_measures = nltk.collocations.BigramAssocMeasures()\\n    Bifinder = BigramCollocationFinder.from_words(w)\\n    Trifinder = TrigramCollocationFinder.from_words(w)\\n    return Bifinder.nbest(bigram_measures.pmi,rank), Trifinder.nbest(trigram_measures.pmi, rank)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def phrase_rank(txt,adds=[],stem_method='snowball',rank=5):\n",
    "    sw=stopword_create(adds)\n",
    "    w=word_tokenize(txt)    \n",
    "    if stem_method=='porter':\n",
    "        ps=PorterStemmer()\n",
    "        w=[ps.stem(i) for i in w if i not in sw]\n",
    "    elif stem_method=='snowball':\n",
    "        ss=SnowballStemmer('english')\n",
    "        w=[ss.stem(i) for i in w if i not in sw]\n",
    "    elif stem_method=='':\n",
    "        w=[i for i in w if i not in sw]\n",
    "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    Bifinder = BigramCollocationFinder.from_words(w)\n",
    "    Trifinder = TrigramCollocationFinder.from_words(w)\n",
    "    return Bifinder.nbest(bigram_measures.pmi,rank), Trifinder.nbest(trigram_measures.pmi, rank)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rake_Analysis(txt):\n",
    "    r1=Rake()\n",
    "    r1.extract_keywords_from_text(txt)\n",
    "    l1=r1.get_ranked_phrases_with_scores()[:10]\n",
    "    r2=RAKE.Rake(RAKE.NLTKStopList())\n",
    "    l2=r2.run(txt)[:10]\n",
    "    \n",
    "    lst=[]\n",
    "    for i in range(10):\n",
    "        lst.append(l1[i][1])\n",
    "        lst.append(l2[i][0])\n",
    "    return set(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst - Requirement of Soft Skills - Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('da_Req_Soft.txt','r') as file:\n",
    "    txt=file.read()\n",
    "txt=txt.replace('•', '')\n",
    "txt=txt.replace('\\n', '')\n",
    "txt=txt.replace('*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corporate missionkey strengths include business',\n",
       " 'cross-divisional projects  strong planning',\n",
       " 'customer service orientation requiredexcellent verbal',\n",
       " 'enhance current ongoing model monitoring process excellent written',\n",
       " 'entrepreneurial environmenthighly motivated self-starterflexible',\n",
       " 'excellent communication skills strong aptitude towards learning new technologies multitasking ability',\n",
       " 'exceptional stakeholder management skills  experience',\n",
       " 'fast paced environment excellent communication skillsbachelor',\n",
       " 'gut check every number',\n",
       " 'including creative problem solving skills',\n",
       " 'industry experienceproven experience effectively prioritizing workload',\n",
       " 'information science/computer science/mathematics/analytics',\n",
       " 'resolve difficult problems without supervisionexcellent analytical thinking',\n",
       " 'solve problems involving several options',\n",
       " 'solving skillssolid project management expertiseoutstanding written',\n",
       " 'united states without visa sponsorship'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rake_Analysis(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'data',\n",
       " 'skills',\n",
       " 'strong',\n",
       " 'experience',\n",
       " 'communications',\n",
       " 'analytics',\n",
       " 'effectively',\n",
       " 'requires',\n",
       " 'managing',\n",
       " 'business',\n",
       " 'working',\n",
       " 'problems',\n",
       " 'science',\n",
       " 'excellent',\n",
       " 'projects',\n",
       " 'writing',\n",
       " 'preferred',\n",
       " 'years',\n",
       " 'technical']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(txt, words=20, split=True, scores=False, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst - Requirement of Tech Skills - Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('da_Req_Tech.txt','r') as file:\n",
    "    txt=file.read()\n",
    "txt=txt.replace('•', '')\n",
    "txt=txt.replace('\\n', '')\n",
    "txt=txt.replace('*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'effectively raise business risks associated',\n",
       " 'experience profiling data within relational data model structures',\n",
       " 'experience using ms accessin-depth knowledge',\n",
       " 'expertise using industry leading data visualization tools',\n",
       " 'formatting dataexperience utilizing reporting toolsbasic sql query development preferredstrong computing',\n",
       " 'forward-thinking individualprior professional services',\n",
       " 'ibm data architect data modeling tools required',\n",
       " 'increasingly responsible data analysis/reporting experience',\n",
       " 'investment banking/private equity backgroundexpertise',\n",
       " 'languagesas arrayslooping – within data step',\n",
       " 'least 7 years experience working mapping',\n",
       " 'meet functional /non-functional business requirements',\n",
       " 'microsoft excel demonstrable client facing experience1',\n",
       " 'perform basic statistical calculations including frequency distributions',\n",
       " 'proc sqlthe data stepmatch-merging',\n",
       " 'quantitative model centered environment experience interfacing',\n",
       " 'sas codesas macro-languagesas arrayslooping',\n",
       " 'sasat least 5 years ’ professional experience using sas programming',\n",
       " 'solve problems involving several options',\n",
       " 'supervised learning machine-learning algorithms nice'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rake_Analysis(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'experience',\n",
       " 'requiring',\n",
       " 'business',\n",
       " 'skills',\n",
       " 'analytic',\n",
       " 'knowledge',\n",
       " 'work',\n",
       " 'reports',\n",
       " 'modelling',\n",
       " 'software',\n",
       " 'sql',\n",
       " 'excellent',\n",
       " 'strong',\n",
       " 'sas',\n",
       " 'analysis',\n",
       " 'statistical',\n",
       " 'including',\n",
       " 'tool',\n",
       " 'tableau']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(txt, words=20, split=True, scores=False, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst - Responsibility of Soft Skills - Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('da_Res_Soft.txt','r') as file:\n",
    "    txt=file.read()\n",
    "txt=txt.replace('•', '')\n",
    "txt=txt.replace('\\n', '')\n",
    "txt=txt.replace('*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business process improvement associate training governance audit',\n",
       " 'compliance business continuity executive communicationbachelor',\n",
       " 'deliver new initiatives research production issues',\n",
       " 'ensure consistent data use across',\n",
       " 'equivalent quantitative field4-6 years',\n",
       " 'facing team – requires good oral',\n",
       " 'host soom omr review meetings',\n",
       " 'implement short-term solutions',\n",
       " 'influence discussions around reporting requirements',\n",
       " 'information-driven setting4+ years',\n",
       " 'might include testing customer feedback channels',\n",
       " 'might include testing new marketing channels',\n",
       " 'multiple independent projects/tasks',\n",
       " 'product design changes cx call flows',\n",
       " 'requestedactively expand consulting skills',\n",
       " 'resolves client issues working',\n",
       " 'solved every single day',\n",
       " 'written communication may support multiple projects'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rake_Analysis(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'business',\n",
       " 'team',\n",
       " 'communities',\n",
       " 'customize',\n",
       " 'working',\n",
       " 'client',\n",
       " 'requires',\n",
       " 'develop',\n",
       " 'solution',\n",
       " 'plans',\n",
       " 'design',\n",
       " 'participating',\n",
       " 'project',\n",
       " 'high',\n",
       " 'productivity',\n",
       " 'new',\n",
       " 'managers',\n",
       " 'analytical']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(txt, words=20, split=True, scores=False, lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyst - Responsibility of Tech Skills - Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('da_Res_Tech.txt','r') as file:\n",
    "    txt=file.read()\n",
    "txt=txt.replace('•', '')\n",
    "txt=txt.replace('\\n', '')\n",
    "txt=txt.replace('*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzing multiwave client experience research results',\n",
       " 'cbre property databaseperforms periodic data audits',\n",
       " 'dashboards using business intelligence tools adhering',\n",
       " 'data gathering techniquesdevelop custom data models',\n",
       " 'data sets using various statistical methodsdevise methods',\n",
       " 'help guide fast-paced decision-makingdata infrastructure',\n",
       " 'implementation including large-scale hadoop deployments',\n",
       " 'large healthcare provider/system data warehousing',\n",
       " 'market intelligence without material dependence',\n",
       " 'minimal supervision develop analytical model',\n",
       " 'optimizing classifiers using machine learning techniquesdata mining using state',\n",
       " 'perform ad hoc marketing analysiscandidate',\n",
       " 'proprietary online analytics tool designed',\n",
       " 'providing as-a-service offerings',\n",
       " 'scalably improving sales outcomesidentify operational weaknesses',\n",
       " 'secure current/correct encounter data necessary',\n",
       " 'third party data sourcesentry level position within data intelligence',\n",
       " 'transform large scale data sets',\n",
       " 'working within tight deadlines evaluate internal data sources',\n",
       " 'write production sas code creating summarized data mart tables supporting crm'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rake_Analysis(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'reporting',\n",
       " 'developed',\n",
       " 'business',\n",
       " 'analytic',\n",
       " 'performs',\n",
       " 'analysis',\n",
       " 'managers',\n",
       " 'includes',\n",
       " 'operations',\n",
       " 'provider',\n",
       " 'researches',\n",
       " 'markets',\n",
       " 'modelling',\n",
       " 'new',\n",
       " 'products',\n",
       " 'client',\n",
       " 'supporting',\n",
       " 'sql',\n",
       " 'team']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(txt, words=20, split=True, scores=False, lemmatize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
